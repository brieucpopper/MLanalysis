{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brieucpopper/miniconda3/envs/tf/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#read the data\n",
    "data=pd.read_csv('tcc_ceds_music.csv')\n",
    "\n",
    "\n",
    "# data report with ydata profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "#get the report\n",
    "\n",
    "#profile = ProfileReport(data, title='Pandas Profiling Report', explorative=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the profile report\n",
    "#profile.to_file(\"your_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "\n",
    "-decision trees w/ pruning (use info gain)\n",
    "-nn\n",
    "-boosting ()\n",
    "-SVM\n",
    "-kNN\n",
    "\n",
    "\n",
    "test on 2 classification problems\n",
    "\n",
    "describe class problems, why they are interesting\n",
    "non trivail but not too hard\n",
    "\n",
    "testing and training rates (graphs)\n",
    "\n",
    "analysis of results\n",
    "\n",
    "max 12 pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chat GPT summary of todo \n",
    "Why?\n",
    "\n",
    "Understand the purpose of the project: Explore supervised learning techniques.\n",
    "Realize that understanding algorithms requires testing them under various conditions.\n",
    "Implement and compare simple learning algorithms.\n",
    "Focus on analysis as the primary goal.\n",
    "The Means\n",
    "\n",
    "Choose datasets for exploration.\n",
    "Tune the selected algorithms.\n",
    "Write a comprehensive analysis.\n",
    "Programming can be done in any language and libraries not specifically designed for this project.\n",
    "Ensure your experiments can be recreated on a standard Linux machine.\n",
    "Acceptable Libraries:\n",
    "\n",
    "Machine learning algorithms: scikit-learn (Python), Weka (Java), e1071/nnet/random forest (R), ML toolbox (Matlab), tensorflow/pytorch (Python).\n",
    "Scientific computing: numpy/scipy (Python), Matlab, R.\n",
    "Plotting: matplotlib (Python), seaborn (Python), Matlab, R.\n",
    "The Problems Given to You\n",
    "\n",
    "Implement five learning algorithms:\n",
    "Decision trees with pruning.\n",
    "Neural networks.\n",
    "Boosting.\n",
    "Support Vector Machines with kernel function swapping.\n",
    "k-nearest neighbors with different k values.\n",
    "Testing\n",
    "\n",
    "Design two classification problems.\n",
    "Ensure they have non-trivial but clear characteristics for analysis.\n",
    "What to Turn In\n",
    "\n",
    "README.txt:\n",
    "Instructions for running your code.\n",
    "Provide URLs to access your code and data.\n",
    "Include necessary files for reproducing your results.\n",
    "yourgtaccount-analysis.pdf:\n",
    "Describe your classification problems and why they are interesting.\n",
    "Report training and testing error rates for each algorithm.\n",
    "Include learning curves (performance vs. training size).\n",
    "Analyze results, comparing and contrasting algorithms.\n",
    "Suggest improvements for each algorithm.\n",
    "Provide timing information (wall clock time and iterations).\n",
    "Explain why you did not implement cross-validation if applicable.\n",
    "Discuss the impact of data, hyperparameters, and other choices.\n",
    "Determine which algorithm performed best and define \"best.\"\n",
    "Keep the analysis concise within a 12-page limit.\n",
    "Scoring Criteria\n",
    "\n",
    "Emphasize your analysis, as it carries the most weight.\n",
    "Implementing code is not as important as understanding and explaining results.\n",
    "Provide thorough but concise explanations.\n",
    "Follow assignment format guidelines strictly.\n",
    "Late submissions will not be accepted, so begin promptly.\n",
    "Rescoring Criteria\n",
    "\n",
    "Review feedback and request a rescore within a week.\n",
    "Provide a clear explanation of where the grader made an error.\n",
    "Failure to gain at least 5 points in a rescore request will result in losing 10 points for not internalizing feedback.\n",
    "Plagiarism and Proper Citations\n",
    "\n",
    "Avoid plagiarism; cite sources properly.\n",
    "Do not use others' code for analysis, as it circumvents the learning process.\n",
    "Engage in the process of exploring, tuning, and analyzing independently.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : understanding the dataset and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "28372 entries\n",
    "release_date : int between 1950 and 2019, no missing values, Will Use\n",
    "genre : string, can take 7 values, no missing values, will use\n",
    "dating : from 0 to 0.64 \n",
    "violence : 0 to 0.98\n",
    "...\n",
    "\n",
    "danceability : 0 to 0.99, normal distribution\n",
    "loudness : kind of normal distribution\n",
    "acousticness : 0 to 1, kind of inverse exponential distribution (lots of very low values)\n",
    "instrumentalness : a lot of zeros, but still 0 to 1\n",
    "\n",
    "valence : same, 0 to 1\n",
    "energy : same, 0 to 1\n",
    "\n",
    "topic : sadness, violence, world/life, obscene, music, night/time, romantic, feelings\n",
    "\n",
    "\n",
    "release_date is highly overall correlated with loudness \n",
    "loudness is highly overall correlated with release_date \n",
    "acousticness is highly overall correlated with loudness \n",
    "energy is highly overall correlated with loudness \n",
    "\n",
    "\n",
    "---> won't use loudness \n",
    "\n",
    "## final columns :\n",
    "\n",
    "release date ---> between -1 and 1 with 0\n",
    "\n",
    "genre : one hot encoded for 7 values (pop, country, blues,jazz,reggae,rock,hip hop)\n",
    "\n",
    "subjects : use them from 0 to 1 as they are (datin, violence, world, night, shake, family, romantic, comm, obscene, music, movement, light, family, like, sadness, feelings)\n",
    "\n",
    "metrics on the song : use them as are (danceablity, acoustincess, intrismetnalness, valence, energy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dating', 'violence', 'world/life', 'night/time', 'shake the audience',\n",
      "       'family/gospel', 'romantic', 'communication', 'obscene', 'music',\n",
      "       'movement/places', 'light/visual perceptions', 'family/spiritual',\n",
      "       'like/girls', 'sadness', 'feelings', 'danceability', 'acousticness',\n",
      "       'instrumentalness', 'valence', 'energy', 'encodedDate', 'genre_blues',\n",
      "       'genre_country', 'genre_hip hop', 'genre_jazz', 'genre_pop',\n",
      "       'genre_reggae', 'genre_rock'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Let's build X and y\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "Xall=data.drop(['Unnamed: 0','artist_name','track_name','lyrics','len','loudness','topic','age'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#create new column encodedDate = (release date-1984.5)/34.5\n",
    "# it is between -1 and 1\n",
    "\n",
    "Xall['encodedDate']=(Xall['release_date']-1984.5)/34.5\n",
    "\n",
    "Xall=Xall.drop(['release_date'],axis=1)\n",
    "\n",
    "#one hot encode the genre\n",
    "Xall=pd.get_dummies(Xall,columns=['genre'])\n",
    "\n",
    "print(Xall.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first problem : predict if the date is before or after 1984.5 (is encodedDate is positive or not)\n",
    "\n",
    "y=Xall['encodedDate']>0\n",
    "\n",
    "X=Xall.drop(['encodedDate'],axis=1)\n",
    "\n",
    "#use a decision tree classifier, get the accuracy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n",
    "\n",
    "# #build the tree with gridsearch for hyperparams, and avoid overfitting\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid={'max_depth':np.arange(2,10),'max_leaf_nodes':np.arange(6,12)}\n",
    "# tree=GridSearchCV(DecisionTreeClassifier(),param_grid,cv=5)\n",
    "# tree.fit(X_train,y_train)\n",
    "# print(tree.best_params_)\n",
    "# print(tree.score(X_test,y_test))\n",
    "\n",
    "#we get 0.67 accuracy with max depth 4 and max leaf nodes 11\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "665/665 [==============================] - 5s 4ms/step - loss: 0.2025 - mse: 0.2025 - accuracy: 0.6891 - val_loss: 0.1829 - val_mse: 0.1829 - val_accuracy: 0.7292\n",
      "Epoch 2/8\n",
      "665/665 [==============================] - 2s 4ms/step - loss: 0.1799 - mse: 0.1799 - accuracy: 0.7285 - val_loss: 0.1794 - val_mse: 0.1794 - val_accuracy: 0.7285\n",
      "Epoch 3/8\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.1774 - mse: 0.1774 - accuracy: 0.7356 - val_loss: 0.1792 - val_mse: 0.1792 - val_accuracy: 0.7296\n",
      "Epoch 4/8\n",
      "665/665 [==============================] - 3s 4ms/step - loss: 0.1765 - mse: 0.1765 - accuracy: 0.7358 - val_loss: 0.1779 - val_mse: 0.1779 - val_accuracy: 0.7293\n",
      "Epoch 5/8\n",
      "665/665 [==============================] - 3s 4ms/step - loss: 0.1748 - mse: 0.1748 - accuracy: 0.7361 - val_loss: 0.1785 - val_mse: 0.1785 - val_accuracy: 0.7318\n",
      "Epoch 6/8\n",
      "665/665 [==============================] - 3s 4ms/step - loss: 0.1745 - mse: 0.1745 - accuracy: 0.7363 - val_loss: 0.1772 - val_mse: 0.1772 - val_accuracy: 0.7330\n",
      "Epoch 7/8\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.1739 - mse: 0.1739 - accuracy: 0.7373 - val_loss: 0.1785 - val_mse: 0.1785 - val_accuracy: 0.7280\n",
      "Epoch 8/8\n",
      "665/665 [==============================] - 3s 4ms/step - loss: 0.1734 - mse: 0.1734 - accuracy: 0.7389 - val_loss: 0.1768 - val_mse: 0.1768 - val_accuracy: 0.7326\n"
     ]
    }
   ],
   "source": [
    "#now onto a simple ANN\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#build the model\n",
    "model=keras.Sequential([\n",
    "    layers.Dense(20,activation='relu',input_shape=[X.shape[1]]),\n",
    "    layers.Dense(10,activation='relu'),\n",
    "    layers.Dense(5,activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mse','accuracy'])\n",
    "\n",
    "#fit the model\n",
    "history=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1768 - mse: 0.1768 - accuracy: 0.7326\n",
      "[0.17675036191940308, 0.17675036191940308, 0.732553243637085]\n"
     ]
    }
   ],
   "source": [
    "#get the accuracy on the test set\n",
    "print(model.evaluate(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7403073452699845\n"
     ]
    }
   ],
   "source": [
    "#now with boosting trees wiht grid CV\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "boost=GradientBoostingClassifier(n_estimators=300,learning_rate=0.1,max_depth=4,random_state=0)\n",
    "boost.fit(X_train,y_train)\n",
    "\n",
    "print(boost.score(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7408712815451854\n"
     ]
    }
   ],
   "source": [
    "#with SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(kernel='rbf',C=1,gamma=1)\n",
    "svm.fit(X_train,y_train)\n",
    "print(svm.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.58%\n"
     ]
    }
   ],
   "source": [
    "k = 75  \n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
